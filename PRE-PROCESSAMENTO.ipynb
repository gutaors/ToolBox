{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXIBINDO MAIS COLUNAS NO HEAD e definindo tamanho das figuras do pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "%pylab inline\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pylab.rcParams['figure.figsize'] = 10, 5\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = 'dados/Iowa House Prices/train.csv' \n",
    "\n",
    "\n",
    "# Fill in the line below to read the file into a variable home_data\n",
    "home_data = iowa_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Review The Data\n",
    "Use the command you learned to view summary statistics of the data. Then fill in variables to answer the following questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseado no describe\n",
    "# What is the average lot size (rounded to nearest integer)?\n",
    "avg_lot_size = 10517\n",
    "\n",
    "# As of today, how old is the newest home (current year - the date in which it was built)\n",
    "newest_home_age = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analisando isNA, null e não null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv('dados/Iowa House Prices/train.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# contagem de isna\n",
    "print(X_full.SalePrice.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# contagem de isnull\n",
    "print(X_full.SalePrice.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "#contagem de nao nulos\n",
    "print(X_full.SalePrice.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../MARIO FILHO/seriestemporaisyt-master/2004-2019.tsv\", sep = '\\t')\n",
    "# Converte data para to_datetime IMPORTANTISSIMO FAZER ISTO, elas abriram como STRINGS\n",
    "dados['DATA INICIAL'] = pd.to_datetime(dados['DATA INICIAL'])\n",
    "dados['DATA FINAL'] = pd.to_datetime(dados['DATA FINAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando os dados para pegar somente oleo diesel (ex de series temporais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copia do dataframe dados para um chamado diesel, pegando só as linhas de oleo diesel\n",
    "diesel = dados[dados['PRODUTO'] == 'ÓLEO DIESEL'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegando somente uma coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define diesel treino e valid\n",
    "diesel_treino = diesel[diesel['DATA FINAL'] < \"2011-01-01\"]\n",
    "diesel_valid = diesel[diesel['DATA FINAL'] >= \"2011-01-01\"]\n",
    "diesel_treino.shape, diesel_valid.shape\n",
    "#define o y para cada dataset, em ambos são o mesmo campo\n",
    "y_treino = diesel_treino['PREÇO MÉDIO REVENDA']\n",
    "y_valid = diesel_valid['PREÇO MÉDIO REVENDA']\n",
    "#print (y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando por períodos de datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9233, 21), (11961, 21))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diesel_treino = diesel[diesel['DATA FINAL'] < \"2011-01-01\"]\n",
    "diesel_valid = diesel[diesel['DATA FINAL'] >= \"2011-01-01\"]\n",
    "diesel_treino.shape, diesel_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegando valores da semana anterior para fazer baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_treino = diesel_treino.groupby(['ESTADO'])['PREÇO MÉDIO REVENDA'].shift(1)\n",
    "baseline_valid = diesel_valid.groupby(['ESTADO'])['PREÇO MÉDIO REVENDA'].shift(1)\n",
    "#joga no dataframe a coluna baseline calculada logo acima \n",
    "diesel_treino['baseline'] = baseline_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando nova feature com as variações de preços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11d302250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simplesmente faz diferença preço de hoje e preço de ontem\n",
    "# a funcao abaixo target_diff recebe uma série e faz a diferença (preço de hoje menos preço de ontem) e retorna\n",
    "# como faz isto? def nomefunc(nomevar):\n",
    "#    retorna a nomevar depois de fazer a difereça  com a nomevar da linha anterior, ou seja, o diff do shift: nomevar.diff().shift(-1) \n",
    "def target_diff(x):\n",
    "    return x.diff().shift(-1) #valor dela mesma menos da linha anterior(-1)\n",
    "\n",
    "# no dataframe, criamos nova coluna df[''], atribuimos a ela o seguinte, agrupamos o preço por estado df.groupby(['ESTADO'])['PRECO'] \n",
    "# com isto criamos a série que vamos passar (aplicar) a def acima\n",
    "\n",
    "diesel_treino['DIFF PREÇO MÉDIO REVENDA'] = diesel_treino.groupby(['ESTADO'])['PREÇO MÉDIO REVENDA'].apply(target_diff)\n",
    "#aqui em cima tem que fazer group by e pegar a linha que queremos (PREÇO MÉDIO REVENDA)\n",
    "\n",
    "diesel_treino.plot(x='DATA FINAL', y='DIFF PREÇO MÉDIO REVENDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando sazonais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o df_X_treino\n",
    "#poe um index em cada dataframe\n",
    "df_X_treino = pd.DataFrame(index=diesel_treino.index)\n",
    "df_X_valid = pd.DataFrame(index=diesel_valid.index)\n",
    "df_X_treino['DIFF_PRECO_MEDIO_REVENDA_PROXIMA_SEMANA'] = diesel_treino.groupby(['ESTADO'])['PREÇO MÉDIO REVENDA'].apply(target_diff)\n",
    "df_X_valid['DIFF_PRECO_MEDIO_REVENDA_PROXIMA_SEMANA'] = diesel_valid.groupby(['ESTADO'])['PREÇO MÉDIO REVENDA'].apply(target_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_X_treino['DIA_DA_SEMANA'] = diesel_treino['DATA FINAL'].dt.weekday\n",
    "df_X_treino['DIA_DO_ANO'] = diesel_treino['DATA FINAL'].dt.dayofyear\n",
    "df_X_treino['SEMANA_DO_ANO'] = diesel_treino['DATA FINAL'].dt.weekofyear\n",
    "\n",
    "\n",
    "df_X_valid['MES'] = diesel_valid['DATA FINAL'].dt.month\n",
    "df_X_valid['DIA'] = diesel_valid['DATA FINAL'].dt.day\n",
    "#df_X_valid['DIA_DA_SEMANA'] = diesel_valid['DATA FINAL'].dt.weekday\n",
    "df_X_valid['DIA_DO_ANO'] = diesel_valid['DATA FINAL'].dt.dayofyear\n",
    "df_X_valid['SEMANA_DO_ANO'] = diesel_valid['DATA FINAL'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will work with data from the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course). \n",
    "\n",
    "![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n",
    "\n",
    "Run the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('dados/Iowa House Prices/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('dados/Iowa House Prices/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to print the first five rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                        \n",
       "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "Id                                    ...                                       \n",
       "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
       "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
       "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
       "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
       "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
       "\n",
       "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "Id                                                                         \n",
       "619         260         0        0       7    2007      New       Partial  \n",
       "871           0         0        0       8    2009       WD        Normal  \n",
       "93            0         0        0       8    2009       WD        Normal  \n",
       "818           0         0        0       7    2008       WD        Normal  \n",
       "303           0         0        0       1    2006       WD        Normal  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset contains both numerical and categorical variables.  You'll need to encode the categorical data before training a model.\n",
    "\n",
    "To compare different models, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Drop columns with categorical data\n",
    "\n",
    "You'll get started with the most straightforward approach.  Use the code cell below to preprocess the data in `X_train` and `X_valid` to remove columns with categorical data.  Set the preprocessed DataFrames to `drop_X_train` and `drop_X_valid`, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lines below: drop columns in training and validation data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_1.hint()\n",
    "#step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Label encoding\n",
    "\n",
    "Before jumping into label encoding, we'll investigate the dataset.  Specifically, we'll look at the `'Condition2'` column.  The code cell below prints the unique entries in both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now write code to: \n",
    "- fit a label encoder to the training data, and then \n",
    "- use it to transform both the training and validation data, \n",
    "\n",
    "you'll get an error.  Can you see why this is the case?  (_You'll need  to use the above output to answer this question._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_2.a.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4aa93e091d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check your answer (Run this code cell to receive credit!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstep_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'step_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "step_2.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue.  For instance, you can write a custom label encoder to deal with new categories.  The simplest approach, however, is to drop the problematic categorical columns.  \n",
    "\n",
    "Run the code cell below to save the problematic columns to a Python list `bad_label_cols`.  Likewise, columns that can be safely label encoded are stored in `good_label_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All categorical columns\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to label encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `label_X_train` and `label_X_valid`, respectively.  \n",
    "- We have provided code below to drop the categorical columns in `bad_label_cols` from the dataset. \n",
    "- You should label encode the categorical columns in `good_label_cols`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply label encoder \n",
    "label_encoder = LabelEncoder()\n",
    "for col in set(good_label_cols):\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "    \n",
    "# Check your answer\n",
    "step_2.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "step_2.b.hint()\n",
    "step_2.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Investigating cardinality\n",
    "\n",
    "So far, you've tried two different approaches to dealing with categorical variables.  And, you've seen that encoding categorical data yields better results than removing columns from the dataset.\n",
    "\n",
    "Soon, you'll try one-hot encoding.  Before then, there's one additional topic we need to cover.  Begin by running the next code cell without changes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows, for each column with categorical data, the number of unique values in the column.  For instance, the `'Street'` column in the training data has two unique values: `'Grvl'` and `'Pave'`, corresponding to a gravel road and a paved road, respectively.\n",
    "\n",
    "We refer to the number of unique entries of a categorical variable as the **cardinality** of that categorical variable.  For instance, the `'Street'` variable has cardinality 2.\n",
    "\n",
    "Use the output above to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many categorical variables in the training data\n",
    "# have cardinality greater than 10?\n",
    "high_cardinality_numcols = 3\n",
    "\n",
    "# Fill in the line below: How many columns are needed to one-hot encode the \n",
    "# 'Neighborhood' variable in the training data?\n",
    "num_cols_neighborhood = 25\n",
    "\n",
    "# Check your answers\n",
    "#step_3.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_3.a.hint()\n",
    "#step_3.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset.  For this reason, we typically will only one-hot encode columns with relatively low cardinality.  Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.\n",
    "\n",
    "As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.  \n",
    "- If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?  \n",
    "- If we instead replace the column with the label encoding, how many entries are added?  \n",
    "\n",
    "Use your answers to fill in the lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-696b5bfd78e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Check your answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstep_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'step_3' is not defined"
     ]
    }
   ],
   "source": [
    "# Fill in the line below: How many entries are added to the dataset by \n",
    "# replacing the column with a one-hot encoding?\n",
    "OH_entries_added = 1e4*100 - 1e4\n",
    "\n",
    "# Fill in the line below: How many entries are added to the dataset by\n",
    "# replacing the column with a label encoding?\n",
    "label_entries_added = 0\n",
    "\n",
    "# Check your answers\n",
    "step_3.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_3.b.hint()\n",
    "#step_3.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: One-hot encoding\n",
    "\n",
    "In this step, you'll experiment with one-hot encoding.  But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.\n",
    "\n",
    "Run the code cell below without changes to set `low_cardinality_cols` to a Python list containing the columns that will be one-hot encoded.  Likewise, `high_cardinality_cols` contains a list of categorical columns that will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to one-hot encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `OH_X_train` and `OH_X_valid`, respectively.  \n",
    "- The full list of categorical columns in the dataset can be found in the Python list `object_cols`.\n",
    "- You should only one-hot encode the categorical columns in `low_cardinality_cols`.  All other categorical columns should be dropped from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#\n",
    "#\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# Check your answer\n",
    "step_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_4.hint()\n",
    "#step_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Generate test predictions and submit your results\n",
    "\n",
    "After you complete Step 4, if you'd like to use what you've learned to submit your results to the leaderboard, you'll need to preprocess the test data before generating predictions.\n",
    "\n",
    "**This step is completely optional, and you do not need to submit results to the leaderboard to successfully complete the exercise.**\n",
    "\n",
    "Check out the previous exercise if you need help with remembering how to [join the competition](https://www.kaggle.com/c/home-data-for-ml-course) or save your results to CSV.  Once you have generated a file with your results, follow the instructions below:\n",
    "1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n",
    "2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n",
    "3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n",
    "4. Click on the **Output** tab on the right of the screen.  Then, click on the blue **Submit** button to submit your results to the leaderboard.\n",
    "\n",
    "You have now successfully submitted to the competition!\n",
    "\n",
    "If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep going\n",
    "\n",
    "With missing value handling and categorical encoding, your modeling process is getting complex. This complexity gets worse when you want to save your model to use in the future. The key to managing this complexity is something called **pipelines**. \n",
    "\n",
    "**[Learn to use pipelines](https://www.kaggle.com/alexisbcook/pipelines)** to preprocess datasets with categorical variables, missing values and any other messiness your data throws at you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Col1  Col2  Col3\n",
      "0    30    31    32\n",
      "1    40    41    42\n",
      "2    50    51    52\n",
      "3     0     0     0\n",
      "4     0     0     0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "# Example 1: Shift values (by row)\n",
    "df1 = pd.DataFrame({'Col1': np.arange(10, 60, 10),\n",
    "                   'Col2': np.arange(11, 61, 10),\n",
    "                   'Col3': np.arange(12, 62, 10)})\n",
    " \n",
    " \n",
    "print(df1.shift(periods=-2).fillna(0).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: shift index\n",
    "ind = pd.date_range('01 / 01 / 2019', periods=5, freq='12H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"A\": [1, 2, 3, 4, 5],\n",
    "                   \"B\": [10, 20, np.nan, 40, 50],\n",
    "                   \"C\": [11, 22, 33, np.nan, 55],\n",
    "                   \"D\": [-11, -24, -51, -36, -2],\n",
    "                   'D1': [False] * 5,\n",
    "                   'E': [True, False, False, True, True]},\n",
    "                  index=ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     A     B     C   D     D1      E\n",
      "2019-01-01 06:00:00  1  10.0  11.0 -11  False   True\n",
      "2019-01-01 18:00:00  2  20.0  22.0 -24  False  False\n",
      "2019-01-02 06:00:00  3   NaN  33.0 -51  False  False\n",
      "2019-01-02 18:00:00  4  40.0   NaN -36  False   True\n",
      "2019-01-03 06:00:00  5  50.0  55.0  -2  False   True\n"
     ]
    }
   ],
   "source": [
    "print(df2.shift(freq='2H', periods=3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      A  B     C     D  D1      E\n",
      "2019-01-01 00:00:00 NaN  1  10.0  11.0 -11  False\n",
      "2019-01-01 12:00:00 NaN  2  20.0  22.0 -24  False\n",
      "2019-01-02 00:00:00 NaN  3   NaN  33.0 -51  False\n",
      "2019-01-02 12:00:00 NaN  4  40.0   NaN -36  False\n",
      "2019-01-03 00:00:00 NaN  5  50.0  55.0  -2  False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example 3: Shift values (by column)\n",
    "print(df2.astype(object).shift(periods=1, axis=1).infer_objects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardinalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importa os dois CSVs, teste e treino\n",
    "X_full = pd.read_csv('Dados/Housing Prices Competition for Kaggle Learn Users/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('Dados/Housing Prices Competition for Kaggle Learn Users/test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# contagem de isnull\n",
    "print(X_full.SalePrice.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#contagem de nao nulos\n",
    "print(X_full.SalePrice.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# contagem de isna\n",
    "print(X_full.SalePrice.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas com a variável alvo faltando, separa alvo e preditores\n",
    "# neste caso nao tinha salesprice nulo então não dá pra ver a função agindo mas se desse os contadores acima ajudariam\n",
    "# dissecando o comando df.dropna(axis=0, subset=['ColunaAlvo'], inplace=True)\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Quebrando validação do treinamento\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lendo dados ( no original atribuia o index mas estava dando erro)\n",
    "#X_full = pd.read_csv('../kaggle/input/train.csv', index_col='Id')\n",
    "#X_test_full = pd.read_csv('../kaggle/input/test.csv', index_col='Id')\n",
    "X_full = pd.read_csv('../kaggle/input/train.csv')\n",
    "X_test_full = pd.read_csv('../kaggle/input/test.csv')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesID</th>\n",
       "      <th>MachineID</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>datasource</th>\n",
       "      <th>auctioneerID</th>\n",
       "      <th>YearMade</th>\n",
       "      <th>MachineHoursCurrentMeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259823</th>\n",
       "      <td>1793554</td>\n",
       "      <td>1112694</td>\n",
       "      <td>9521</td>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296305</th>\n",
       "      <td>2228525</td>\n",
       "      <td>896820</td>\n",
       "      <td>23931</td>\n",
       "      <td>136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148817</th>\n",
       "      <td>1522036</td>\n",
       "      <td>1452830</td>\n",
       "      <td>4199</td>\n",
       "      <td>132</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99268</th>\n",
       "      <td>1416913</td>\n",
       "      <td>1178673</td>\n",
       "      <td>3357</td>\n",
       "      <td>132</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160662</th>\n",
       "      <td>1580944</td>\n",
       "      <td>1430028</td>\n",
       "      <td>8308</td>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SalesID  MachineID  ModelID  datasource  auctioneerID  YearMade  \\\n",
       "259823  1793554    1112694     9521         132           1.0      1989   \n",
       "296305  2228525     896820    23931         136           NaN      1998   \n",
       "148817  1522036    1452830     4199         132           2.0      1989   \n",
       "99268   1416913    1178673     3357         132           2.0      1982   \n",
       "160662  1580944    1430028     8308         132           1.0      1977   \n",
       "\n",
       "        MachineHoursCurrentMeter  \n",
       "259823                       NaN  \n",
       "296305                       0.0  \n",
       "148817                       NaN  \n",
       "99268                        NaN  \n",
       "160662                       NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape e Missing Values (faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5e2c1c513f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Shape of training data (num_rows, num_columns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Number of missing values in each column of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmissing_val_count_by_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preenchendo valores em branco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-eb4ae6f0706b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numero de linhas total, numero de colunas com missing, número total de missing\n",
    "\n",
    "Use the above output to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many rows are in the training data?\n",
    "num_rows = 1168\n",
    "\n",
    "# Fill in the line below: How many columns in the training data\n",
    "# have missing values?\n",
    "num_cols_with_missing = 3\n",
    "\n",
    "# Fill in the line below: How many missing entries are contained in \n",
    "# all of the training data?\n",
    "tot_missing = 276\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cria um score para depois Imputar ou dropar os Missing Values e ver como afeta o Score\n",
    "Considering your answers above, what do you think is likely the best approach to dealing with the missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_1.b.hint()\n",
    "#Como há relativamente poucas entradas faltantes nos dados\n",
    "# a coluna com maior percentual de valores faltantes\n",
    "# tem menos de 20% faltantes, neste caso,  dropar colunas provavelmente não dá bons resultados\n",
    "# pois estaríamos jogando fora um monte de daos valiosos\n",
    "# Neste caso IMPUTAR VALORES funciona melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Drop columns with missing values\n",
    "In this step, you'll preprocess the data in X_train and X_valid to remove columns with missing values. Set the preprocessed DataFrames to reduced_X_train and reduced_X_valid, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: get names of columns with missing values\n",
    "# Your code here\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Fill in the lines below: drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Drop columns with missing values):\n",
      "7026.521957494546\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Imputation\n",
    "Part A\n",
    "Use the next code cell to impute missing values with the mean value along each column. Set the preprocessed DataFrames to imputed_X_train and imputed_X_valid. Make sure that the column names match those in X_train and X_valid.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[28]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "# Your code here\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell without changes to obtain the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Imputation):\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gustavorodriguessilveira/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-59-c3091894c920>\", line 2, in <module>\n",
      "    print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n",
      "  File \"<ipython-input-15-2698d73d4825>\", line 7, in score_dataset\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 1007, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 375, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gustavorodriguessilveira/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gustavorodriguessilveira/Library/Python/3.7/lib/python/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/gustavorodriguessilveira/Library/Python/3.7/lib/python/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/gustavorodriguessilveira/Library/Python/3.7/lib/python/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/gustavorodriguessilveira/Library/Python/3.7/lib/python/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/tokenize.py\", line 447, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part B\n",
    "\n",
    "Compare the MAE from each approach.  Does anything surprise you about the results?  Why do you think one approach performed better than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate test predictions\n",
    "\n",
    "In this final step, you'll use any approach of your choosing to deal with missing values.  Once you've preprocessed the training and validation features, you'll train and evaluate a random forest model.  Then, you'll preprocess the test data before generating predictions that can be submitted to the competition!\n",
    "\n",
    "### Part A\n",
    "\n",
    "Use the next code cell to preprocess the training and validation data.  Set the preprocessed DataFrames to `final_X_train` and `final_X_valid`.  **You can use any approach of your choosing here!**  in order for this step to be marked as correct, you need only ensure:\n",
    "- the preprocessed DataFrames have the same number of columns,\n",
    "- the preprocessed DataFrames have no missing values, \n",
    "- `final_X_train` and `y_train` have the same number of rows, and\n",
    "- `final_X_valid` and `y_valid` have the same number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed training and validation features\n",
    "final_imputer = SimpleImputer(strategy='median')\n",
    "final_X_train = pd.DataFrame(final_imputer.fit_transform(X_train))\n",
    "final_X_valid = pd.DataFrame(final_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "final_X_train.columns = X_train.columns\n",
    "final_X_valid.columns = X_valid.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the next code cell to train and evaluate a random forest model. (Note that we don't use the score_dataset() function above, because we will soon use the trained model to generate test predictions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)\n",
    "\n",
    "# Get validation predictions and MAE\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "print(\"MAE (Your approach):\")\n",
    "print(mean_absolute_error(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Use the next code cell to preprocess your test data.  Make sure that you use a method that agrees with how you preprocessed the training and validation data, and set the preprocessed test features to `final_X_test`.\n",
    "\n",
    "Then, use the preprocessed test features and the trained model to generate test predictions in `preds_test`.\n",
    "\n",
    "In order for this step to be marked correct, you need only ensure:\n",
    "- the preprocessed test DataFrame has no missing values, and\n",
    "- `final_X_test` has the same number of rows as `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: preprocess test data\n",
    "final_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
    "\n",
    "# Fill in the line below: get test predictions\n",
    "preds_test = model.predict(final_X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run the next code cell without changes to save your results to a CSV file that can be submitted directly to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 5: Submit your results\n",
    "Once you have successfully completed Step 4, you're ready to submit your results to the leaderboard! (You also learned how to do this in the previous exercise. If you need a reminder of how to do this, please use the instructions below.)\n",
    "\n",
    "First, you'll need to join the competition if you haven't already. So open a new window by clicking on this link. Then click on the Join Competition button.\n",
    "Next, follow the instructions below: 1. Begin by clicking on the blue Save Version button in the top right corner of the window. This will generate a pop-up window.\n",
    "2. Ensure that the Save and Run All option is selected, and then click on the blue Save button. 3. This generates a window in the bottom left corner of the notebook. After it has finished running, click on the number to the right of the Save Version button. This pulls up a list of versions on the right of the screen. Click on the ellipsis (...) to the right of the most recent version, and select Open in Viewer. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions. 4. Click on the Output tab on the right of the screen. Then, click on the blue Submit button to submit your results to the leaderboard.\n",
    "\n",
    "You have now successfully submitted to the competition!\n",
    "\n",
    "If you want to keep working to improve your performance, select the blue Edit button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit2ee93546cde34f6daeca7b593a4498be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
