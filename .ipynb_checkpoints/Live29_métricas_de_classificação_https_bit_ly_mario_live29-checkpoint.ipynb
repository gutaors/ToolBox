{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3HvlFpYZWAU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqMpT0C9Z8tI"
   },
   "source": [
    "80/20 - pareto\n",
    "- Essas métricas vão resolver a maioria dos problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9zVHZODag0T"
   },
   "outputs": [],
   "source": [
    "np.random.seed(50)\n",
    "p_binary = np.random.uniform(size=10) #mdl.predict_proba\n",
    "p_multi = np.random.uniform(size=(10,3))\n",
    "\n",
    "y_binary = (np.random.uniform(size=10) > 0.5).astype(int)\n",
    "y_multi = np.random.uniform(size=(10, 3)).argmax(axis=1)\n",
    "\n",
    "p_binary_threshold = (p_binary > 0.5).astype(int)\n",
    "p_multi_argmax = p_multi.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6bLrY8vdjmF"
   },
   "source": [
    "# Precisam de ponto de corte\n",
    "- mdl.predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaulrFzAeSvx"
   },
   "source": [
    "## Acurácia\n",
    "- não use \"oficialmente\", apenas \"preguiçosamente\"\n",
    "- inadequada para dados desequilibrados\n",
    "- 99,76% - não são spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "P0UjgecOdSId",
    "outputId": "da6b9b1e-92fa-40e1-aaad-52e86d5b55d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [0 0 0 0 0 1 0 1 1 0]\n",
      "Y = [1 1 1 0 1 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"P = {}\\nY = {}\".format(p_binary_threshold, y_binary))\n",
    "\n",
    "accuracy_score(y_binary, p_binary_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twa26VOTfncD"
   },
   "source": [
    "# Precision\n",
    "- dos casos que eu previ como positivos (para uma classe) quantos realmente são?\n",
    "- Envio de cupons de desconto, custos diferentes para cada erro.\n",
    "- Ex: se custa caro mandar a promoção, das pessoas que eu previ que iam comprar, quantas compraram?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "o5kmtOfTe2_v",
    "outputId": "e69842f0-288b-4e0b-c860-8177baf7ae1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [0 0 0 0 0 1 0 1 1 0]\n",
      "Y = [1 1 1 0 1 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(\"P = {}\\nY = {}\".format(p_binary_threshold, y_binary))\n",
    "\n",
    "precision_score(y_binary, p_binary_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpTaj8A9hGRN"
   },
   "source": [
    "# Recall\n",
    "- dos que eram realmente positivos (para uma classe) quantos eu detectei?\n",
    "- taxa de detecção\n",
    "- https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "vRb6pddLgFOI",
    "outputId": "4940b61b-836f-4ee6-b117-a71c59175703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [0 0 0 0 0 1 0 1 1 0]\n",
      "Y = [1 1 1 0 1 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(\"P = {}\\nY = {}\".format(p_binary_threshold, y_binary))\n",
    "\n",
    "recall_score(y_binary, p_binary_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nT9zVoGidW9"
   },
   "source": [
    "# F1 Score\n",
    "- média harmônica entre os dois  \n",
    "( 2 * precision * recall ) / (precision + recall) \n",
    "https://en.wikipedia.org/wiki/F1_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "C_6Nlh1bhfKh",
    "outputId": "121fda11-d065-4074-e914-4af6911d905c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [0 0 0 0 0 1 0 1 1 0]\n",
      "Y = [1 1 1 0 1 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"P = {}\\nY = {}\".format(p_binary_threshold, y_binary))\n",
    "#(2 * .67 * .2857) / (.67 + .2857)\n",
    "\n",
    "f1_score(y_binary, p_binary_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YTmHiD13i6FJ",
    "outputId": "de23ff2f-8918-4855-e804-6864bae175ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4005838652296746"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kocugLaVjOu3"
   },
   "source": [
    "# Kappa\n",
    "- It is generally thought to be a more robust measure than simple percent agreement calculation, as κ takes into account the possibility of the agreement occurring by chance\n",
    "- leia mais sobre ela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "l_rHkhMxjAya",
    "outputId": "bc3cd4c7-ab7b-420a-ac1b-7004bcae84f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [1 0 1 2 0 1 2 1 0 0]\n",
      "Y = [1 1 1 1 2 2 0 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.09375"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print(\"P = {}\\nY = {}\".format(p_multi_argmax, y_multi))\n",
    "\n",
    "cohen_kappa_score(y_multi, p_multi_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udhVALlvjxLe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOxMtvqWlBbR"
   },
   "source": [
    "# Avalia a probabilidadade diretamente (sem ponto de corte)\n",
    "- mdl.predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey5w_1vdlNCd"
   },
   "source": [
    "# Log Loss\n",
    "- calculada para a probabilidade empírica do evento. Proporção que o evento ocorre na vida real\n",
    "- Se o time A jogar contra o time B e tiver 40% de chances de ganhar, se jogarem 10 vezes, 4 vezes o time A vai ganhar.\n",
    "- A log loss estará na mínima quando o modelo prever 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "OVzkEHLvlLoS",
    "outputId": "b71071e9-e9d9-4cf0-994e-790daa50a1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [0.49460165 0.2280831  0.25547392 0.39632991 0.3773151  0.99657423\n",
      " 0.4081972  0.77189399 0.76053669 0.31000935]\n",
      "Y = [1 1 1 0 1 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8048274348871413"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print(\"P = {}\\nY = {}\".format(p_binary, y_binary))\n",
    "\n",
    "p_random = np.ones(10) * 0.5\n",
    "\n",
    "log_loss(y_binary, p_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_shnSa77m2_7"
   },
   "source": [
    "# ROC AUC\n",
    "- qual é a chance de um exemplo positivo ter um score (previsão) maior do que um negativo?\n",
    "- bom quando garantir que positivos sejam rankeados acima dos negativos é mais importante do que prever a probabilidade real do evento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "RiZGG05TmKZh",
    "outputId": "e594a613-a5f4-44ca-b71e-876edb4ff32f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [0.49460165 0.2280831  0.25547392 0.39632991 0.3773151  0.99657423\n",
      " 0.4081972  0.77189399 0.76053669 0.31000935]\n",
      "Y = [1 1 1 0 1 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4761904761904762"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"P = {}\\nY = {}\".format(p_binary, y_binary))\n",
    "\n",
    "roc_auc_score(y_binary, p_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "q-bBwjyOmaMw",
    "outputId": "c650fb0a-d4f8-4447-d269-08680adc7e62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47757"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_over = 0\n",
    "total = 100000\n",
    "\n",
    "for i in range(total):\n",
    "  caixa_de_positivos = p_binary[y_binary == 1]\n",
    "  caixa_de_negativos = p_binary[y_binary == 0]\n",
    "\n",
    "  positivo = np.random.choice(caixa_de_positivos, size=1, replace=False)\n",
    "  negativo = np.random.choice(caixa_de_negativos, size=1, replace=False)\n",
    "\n",
    "  if positivo > negativo:\n",
    "    sum_over += 1\n",
    "sum_over / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijHo0ufnpMCv"
   },
   "source": [
    "# AUPRC - Area Under the Precision-Recall Curve\n",
    "- acho mais estável e mais fácil de interpretar\n",
    "- AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "V9lgYBr0o4Fi",
    "outputId": "3e48b1d0-f78a-4673-dec6-f8028d17a6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = [0.49460165 0.2280831  0.25547392 0.39632991 0.3773151  0.99657423\n",
      " 0.4081972  0.77189399 0.76053669 0.31000935]\n",
      "Y = [1 1 1 0 1 1 1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7568027210884354"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "print(\"P = {}\\nY = {}\".format(p_binary, y_binary))\n",
    "\n",
    "average_precision_score(y_binary, p_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "irT-nIGTpxd4",
    "outputId": "21439207-b842-49c0-82dc-eb92e55db5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.33      0.29         3\n",
      "           1       0.50      0.40      0.44         5\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.25      0.24      0.24        10\n",
      "weighted avg       0.33      0.30      0.31        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_multi, p_multi_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rowRScoOqYQ1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Live29 - métricas de classificação - https://bit.ly/mario-live29",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
